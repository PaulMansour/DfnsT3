'{rslt} ← {larg} (fun ##.ticks) rarg         ⍝ Sample Dfn execution clock ticks.⍞000D⍞000DDuring  code execution, ⎕AI''s "compute time" clock ticks every so-many millisec-⍞000Donds. Operator [ticks] records which line in its operand [fun]ction is executing⍞000Das each tick occurs and reports the percentage of ticks that fall on each line.⍞000D⍞000DIn order to obtain a significant tick-sample, the function is applied repeatedly⍞000Dto (or between) its argument(s) until the clock has ticked 1,000 times. Repeated⍞000Dapplication means that any side effects (⎕nappend, etc) will also be perpetrated⍞000Drepeatedly, which may be undesirable.⍞000D⍞000DAt  the  end of the time period, the function source is displayed in the session⍞000Dtogether with, for each line:⍞000D⍞000D- The number of times the line was "visited".⍞000D- The percentage of clock ticks recorded for the line.⍞000D⍞000D    ┌────────────── visits⍞000D    │  ┌─────────── percent⍞000D    │  │  ┌──────── source⍞000D    │  │  │⍞000D    5 14  sieve←{             ⍝ Sieve of Eratosthenes.⍞000D    5 15      ⍺←⍬             ⍝ Default no primes yet.⍞000D    5 14      nxt←1↑⍵         ⍝ Next prime, and⍞000D    5 14      msk←×nxt|⍵      ⍝ ... mask of non-multiples.⍞000D    5 17      ∧/1↓msk:⍺,⍵     ⍝ All non multiples - finished.⍞000D    4 26      (⍺,nxt)∇ msk/⍵  ⍝ Sieve remainder.⍞000D    0  0  }⍞000D⍞000DWhere:⍞000D⍞000D- Visits:  This  is (intended to be) an accurate account of the number visits to⍞000D  each  line. A line containing a local function is deemed to be visited both at⍞000D  definition  and application time. This behaviour differs from that of operator⍞000D  →mdf←,  which  reports  only  the  definition count in such cases. See Bugs[6]⍞000D  below.⍞000D⍞000D- Percent:  Approximate  indication of the proportion of clock ticks occuring in⍞000D  each  line.  Owing to timing granularity, the column total may not be 100; see⍞000D  below.⍞000D⍞000D- Source:  As  much of the subject function''s source code as will fit across the⍞000D  screen.⍞000D⍞000DUnlike  ⎕MONITOR  used with traditional functions, the time attributed to a line⍞000D_excludes_ that spent in called subfunctions. This is a _good_thing_.⍞000D⍞000D⎕AI''s  clock resolution varies: on some systems, the clock ticks every 10 milli-⍞000Dseconds  and on others, every 16 (or so). In any case, many lines of code may be⍞000Dexecuted  between  ticks. The best we can do is to run the function for a period⍞000Dof time and notice on which lines the ticks occur.⍞000D⍞000DThe  following  diagram illustrates the problem: each ┼────┼ represents the real⍞000Dand varying execution time of successive lines of code, and ↑tick shows the reg-⍞000Dular clock ticks occuring.⍞000D⍞000D⍞000D    ─┼───┼──┼─┼────┼────┼───┼─┼──┼─┼─┼────────┼──────────┼──────┼─────┼─┼───┼⍞000D    ↑                       ↑                       ↑                       ↑⍞000D    tick                    tick                    tick                    tick⍞000D⍞000DTo  interpret  the  result as an indication of relative processing time for each⍞000Dline,  we  must suppose that, in general, lines that take longer to execute will⍞000Dsustain proportionally more ticks.⍞000D⍞000DBugs:⍞000D⍞000D[1] The  time taken to execute the monitoring code often vastly exceeds the time⍞000D    taken  to execute the code it is monitoring. This would be OK if the monitor⍞000D    took  _exactly_ the same time to execute on each occasion, in which case, we⍞000D    could  calculate and subtract the overhead. However, in Dyalog APL, the heap⍞000D    manager may take a different number of cycles to satisfy a request depending⍞000D    on  the  state  of  fragmentation  of  the heap. This means that attempts to⍞000D    account  for  the execution time overhead of the monitoring code can be only⍞000D    approximate.⍞000D⍞000D[2] If  the  (copy  of the) subject function, with its embedded monitoring code,⍞000D    happens  to  run  in  a time that is an exact multiple of the system clock''s⍞000D    resolution,  all  bets are off as ticks would tend to accumulate in the same⍞000D    few lines.⍞000D⍞000D[3] The generated monitoring function (⍙_f) will fail with a SYNTAX ERROR if any⍞000D    local function call does not produce a result. For example:⍞000D⍞000D        loop←{⍞000D            0<⍵:∇ ⍵-1⍞000D        }⍞000D⍞000D[4] During  execution  of  the  subject function, tail-calling is disabled. This⍞000D    means  that a "highly iterative" function such as the following will produce⍞000D    misleading results:⍞000D⍞000D        loop←{⍞000D            ⍵=0:⍵           ──── comparision with 0 _should_ be⍞000D            ∇ ⍵-1           ──── commensurate with subtraction of 1.⍞000D        }⍞000D⍞000D        loop ticks 1e3⍞000D    1001 15  loop←{⍞000D    1001 14      ⍵=0:⍵⍞000D    1000 71      ∇ ⍵-1⍞000D       0  0  }⍞000D⍞000D[5] As  the monitoring code is merged into a copy of the subject function, there⍞000D    is potential for a name clash. The presence of any of the following names in⍞000D    the subject function will lead to unpredictable results:⍞000D⍞000D        ⍙_a   ⍙_e   ⍙_f   ⍙_l⍞000D        ⍙_m   ⍙_n   ⍙_q   ⍙_s⍞000D        ⍙_t   ⍙_x   ⍙_z⍞000D        ⍙_    _⍙⍞000D⍞000D[6] The  line  visits counter is incremented whenever the entry monitor code de-⍞000D    tects  that the line number (⎕LC) has changed. Such is the case when a local⍞000D    function  is invoked from a line other than its definition line. Compare the⍞000D    following examples:⍞000D⍞000D⍞000D    1 ··  dup1←{⍞000D    3 ··      dup←{⍵ ⍵}         ──── 3 visits: 1 definition +⍞000D    1 ··      a←dup ⍵           ────           1 call +⍞000D    1 ··      dup a             ────           1 more call.⍞000D    0 ··  }⍞000D⍞000D⍞000D    1 ··  dup2←{⍞000D    1 ··      dup←{⍵ ⍵} ⋄ a←dup ⍵ ⋄ dup a       ─── 1 visit to line.⍞000D    0 ··  }⍞000D⍞000D⍞000D    1 ··  dup3←{⍞000D    2 ··      dup←{⍵ ⍵}         ──── 2 visits: 1 definition +⍞000D    1 ··      dup dup ⍵         ────           1 (double) call.⍞000D    0 ··  }⍞000D⍞000D⍞000D    1 ··  dup4←{⍞000D    1 ··      {⍵ ⍵}{⍵ ⍵}⍵       ──── 1 visit to line.⍞000D    0 ··  }⍞000D⍞000D⍞000D    1 ··  dup5←{⍞000D    2 ··      {                 ──── 2 visits: 1 definition +⍞000D    1 ··          ⍵ ⍵           ────           1 call.⍞000D    1 ··      }{⍞000D    1 ··          ⍵ ⍵⍞000D    0 ··      }⍵⍞000D    0 ··  }⍞000D⍞000D⍞000D    1 ··  dup6←{⍞000D    1 ··      {⍵ ⍵}¨⍵ ⍵         ──── 1 visit to line.⍞000D    0 ··  }⍞000D⍞000D⍞000D[7] When  the execution path through the subject function is determined by fact-⍞000D    ors  other  than  its arguments, the first (visits) column of the result may⍞000D    contain  non-integers.  This  might  be the case, for example, if ⎕TS or ⎕RL⍞000D    were used within the function, as with:⍞000D⍞000D        maze ticks 10 20        ⍝ reports non-integral line visits count.⍞000D⍞000D    Such a result might be interpreted as an _average_ number of line visits.⍞000D⍞000DTechnical notes:⍞000D⍞000DThe  coding  of  [ticks] is fairly ghastly for the same reason as →mdf←. See the⍞000Dtechnical notes in →mdf← for details.⍞000D⍞000DMonitoring is achieved in several stages:⍞000D⍞000D- A copy of the subject function is injected with entry (→⍵) and exit (⍺←) mark-⍞000D  ers  at  the  start of each line and at the entry and exit points of each sub-⍞000D  function. These  markers are subsequently replaced with calls to the entry and⍞000D  exit monitoring sequences:⍞000D⍞000D    ⍙_ ⍵: ⋄ ··· ⍝ entry sequence.⍞000D    ⍺ _⍙ ···    ⍝ exit sequence,⍞000D⍞000D  where  ⍺  and ⍵ are replaced with the number of the function line in which the⍞000D  sequence  appears. Monitoring function ⍙_ returns 0 (so that its guard is ign-⍞000D  ored) and _⍙ returns its right argument as the result of the (sub-) function.⍞000D⍞000D- A small loop is executed to determine ⎕AI''s clock resolution and therefore the⍞000D  time needed to endure 1,000 clock ticks.⍞000D⍞000D- The  doctored  function  is  executed  repeatedly for this time period, during⍞000D  which sampling information is accumulated in the operator''s local variables:⍞000D⍞000D    ⍙_t     time accumulated per line.⍞000D    ⍙_n     number of times line is visited (first column of resulting display).⍞000D    ⍙_e     number of times entry monitor is called.⍞000D    ⍙_x         ..      ..  exit    ..      ..⍞000D⍞000D  The  copy  (⍙_f)  of  the subject function is applied under ⍎ in order to defy⍞000D  Dfns'' "strictly local to the capsule" rule that would otherwise put the accum-⍞000D  ulating variables beyond its scope.⍞000D⍞000D- An  attempt is made to calculate the time overhead spent within the monitoring⍞000D  code  itself.  This  is  effected by timing loops with embedded entry and exit⍞000D  sequences. Note that these loops are "compiled" by using ⍎, so that they bene-⍞000D  fit  from the same interpreter performance improvements, if any (such as idiom⍞000D  recognition), as the monitored subject function.⍞000D⍞000D- Finally, this approximate monitoring overhead is subtracted from the monitored⍞000D  times  and  the  result displayed using ⎕←. The result of the subject function⍞000D  application is returned as a shy result, so that [ticks] may easily be embedd-⍞000D  ed within any expression; see the tube.dws example below.⍞000D⍞000DExamples:⍞000D⍞000D⍝ Ackermann''s  function  is a challenging case, as the processing time is⍞000D⍝ _negligible_ compared with the monitoring overhead. Repeated monitoring⍞000D⍝ of this function often shows quite disparate timing.⍞000D⍞000D      3 ack ticks 3⍞000D2432 23  ack←{⍞000D2432 22      ⍺=0:⍵+1⍞000D1244 14      ⍵=0:(⍺-1)∇ 1⍞000D1187 41          (⍺-1)∇ ⍺ ∇ ⍵-1⍞000D   0  0  }⍞000D⍞000D      3 ack ticks 3⍞000D2432 22  ack←{⍞000D2432 24      ⍺=0:⍵+1⍞000D1244 16      ⍵=0:(⍺-1)∇ 1⍞000D1187 38          (⍺-1)∇ ⍺ ∇ ⍵-1⍞000D   0  0  }⍞000D⍞000D⍝ However,  for more substatial functions, the display can be illuminating. Here⍞000D⍝ is the output from a graph searching function in tube.dws. Inserting a call on⍞000D⍝ ticks  into  the  trip function, shows that around 80% of its time is spent in⍞000D⍝ determining which vertices are free.⍞000D⍝⍞000D⍝   trip[19]  find←⍺.graph{⍺⍺ path ticks ⍺ ⍵}       ⍝ find one leg of the route.⍞000D⍝                                  ¯¯¯¯¯⍞000D⍞000D    london trip ''Hammersmith'' ''Mornington''⍞000D  1  0  path←{                      ⍝ Shortest path from/to ⍵ in graph ⍺.⍞000D  1  0      graph←⍺                 ⍝ ⍺ is graph vector.⍞000D  1  0      fm to←⍵                 ⍝ starting and target vertex(ices).⍞000D  1  1      tree←¯2+(⍳⍴⍺)∊fm        ⍝ initial spanning tree.⍞000D573 80      free←{(¯2=tree[⍵])/⍵}   ⍝ free vertices in ⍵.⍞000D 20  1      ⍬{                      ⍝ path accumulator.⍞000D 19  1          ⍵<0:(⍵=¯2)↓⍺        ⍝ root or unvisited vertex: finished.⍞000D 18  3          (⍵,⍺)∇ ⍵⊃tree       ⍝ otherwise: prefix previous (parent) vertex⍞000D 18  1      }{                      ⍝ find partial spanning tree:⍞000D 18  1          ⍵≡⍬:¯1              ⍝ no vertices left: stitched.⍞000D 18  1          1∊to∊⍵:1↑⍵∩to       ⍝ found target: finished.⍞000D 17  1          next←free¨graph[⍵]  ⍝ next vertices to visit.⍞000D 17  4          back←↑,/⍵+0×next    ⍝ back links.⍞000D 17  1          wave←↑,/next        ⍝ vertex wave front.⍞000D 17  1          tree[wave]←back     ⍝ set back links in tree.⍞000D 17  3          ∇∪wave              ⍝ advance wave front.⍞000D  0  0      }fm                     ⍝ from starting vertex.⍞000D  0  0  }⍞000DHammersmith⍞000D    Hammersmith         Piccadilly⍞000D    Barons Court        Piccadilly⍞000D    Earl''s Court        Piccadilly⍞000D    Gloucester Road     Piccadilly⍞000D    South Kensington    Piccadilly⍞000D    Knightsbridge       Piccadilly⍞000D    Hyde Park Corner    Piccadilly⍞000D    Green Park          Piccadilly⍞000DGreen Park⍞000D    Green Park          Victoria⍞000D    Oxford Circus       Victoria⍞000D    Warren Street       Victoria⍞000D    Euston              Victoria⍞000DEuston⍞000D    Euston              Northern⍞000D    Mornington Crescent Northern⍞000DMornington Crescent⍞000D⍞000D⍝ This example uses Hungarian Assignment on a 100×100 matrix. Note that just⍞000D⍝ four of the lines account for around 60% of processing time:⍞000D⍞000D      assign ticks ?100 100⍴1000⍞000D  1  0  assign←{⎕ML←0                               ⍝ Hungarian method cost assi⍞000D  1  0⍞000D  2  0      step0←{step1(⌽⌈\⌽⍴⍵)↑⍵}                 ⍝ 0: at least as many rows a⍞000D  1  0⍞000D  2  0      step1←{step2↑(↓⍵)-⌊/⍵}                  ⍝ 1: reduce rows by minimum⍞000D  1  0⍞000D  2  0      step2←{                                 ⍝ 2: mark independent zeros.⍞000D  4  0          stars←{                             ⍝ independent zeros.⍞000D  3  0              ~1∊⍵:⍺                          ⍝ no more zeros: done.⍞000D  2  0              next←<\<⍀⍵                      ⍝ more independent zeros.⍞000D  2  0              mask←(rows next)∨cols next      ⍝ mask of dependent rows and⍞000D  2  0              (⍺∨next)∇ ⍵>mask                ⍝ ⍺-accumulated star matrix.⍞000D  0  0          }                                   ⍝⍞000D  2  0          zeros←{⍵+0 stars ⍵}⍵=0              ⍝ 1=>zero, 2=>independent ze⍞000D  1  0          step3 ⍵ zeros                       ⍝ next step: 3.⍞000D  0  0      }⍞000D  1  0⍞000D 41  0      step3←{costs zeros←⍵                    ⍝ 3: cover cols with starred⍞000D 40  0          stars←zeros=2                       ⍝ starred zeros.⍞000D 40  0          covers←2×cols stars                 ⍝ covered cols.⍞000D 40  0          ~0∊covers:stars                     ⍝ all cols covered: solution⍞000D 39  0          step4 costs zeros covers            ⍝ next step: 4.⍞000D  0  0      }⍞000D  1  0⍞000D828  1      step4←{costs zeros covers←⍵             ⍝ 4: adjust covering lines.⍞000D827  3          mask←covers=0                       ⍝ mask of uncovered elements⍞000D827  5          open←1=mask×zeros                   ⍝ uncovered zeros.⍞000D827  5          ~1∊open:(⌊/(,mask)/,costs)step6 ⍵   ⍝ no uncovered zeros, next s⍞000D767  1          prime←first open                    ⍝ choose first uncovered zer⍞000D767  1          prow←rows prime                     ⍝ row containing prime.⍞000D767  6          star←2=zeros×prow                   ⍝ star in row containing pri⍞000D806  6          ~1∊star:prime step5{                ⍝ no star in row, next step⍞000D 39  0              costs ⍵ prime                   ⍝ adjusted zeros matrix,⍞000D  0  0          }zeros+2×prime                      ⍝ new primed zero (3).⍞000D728  1          cnext←covers+prow-2×cols star       ⍝ adjusted covers.⍞000D728  6          znext←zeros⌈3×prime                 ⍝ primed zero.⍞000D728  4          ∇ costs znext cnext                 ⍝ adjusted zeros and covers⍞000D  0  0      }⍞000D  1  0⍞000D109  0      step5←{costs zeros prime←⍵              ⍝ 5: exchange starred zeros.⍞000D108  1          star←(cols prime)∧zeros=2           ⍝ next star.⍞000D147  0          ~1∊star:step3 ⍺{                    ⍝ no stars: next step :3.⍞000D117  1              {costs ⍵}{⍵-2×⍵=3}⍵-⍺∧⍵>1       ⍝ unstarred stars; starred p⍞000D  0  0          }zeros                              ⍝ adjusted zero markers.⍞000D 69  0          pnext←(rows star)∧zeros=3           ⍝ next prime.⍞000D 69  0          (⍺∨pnext∨star)∇ costs zeros pnext   ⍝ ⍺-accumulated prime-star-·⍞000D  0  0      }⍞000D  1  0⍞000D 61  0      step6←{costs zeros covers←⍵             ⍝ 6: adjust cost matrix.⍞000D 60 20          cnext←costs+⍺×¯1 1+.×0 3∘.=covers   ⍝ add and subtract minimum v⍞000D 60  1          znext←zeros+(×costs)-×cnext         ⍝ amended zeros marker.⍞000D 60  0          step4 cnext znext covers            ⍝ next step: 4.⍞000D  0  0      }⍞000D  1  0⍞000D839 15      rows←{(⍴⍵)⍴(⊃⌽⍴⍵)/∨/⍵}                  ⍝ row propagation.⍞000D879 12      cols←{(⍴⍵)⍴∨⌿⍵}                         ⍝ column propagation.⍞000D768 12      first←{(⍴⍵)⍴<\,⍵}                       ⍝ first 1 in bool matrix.⍞000D  1  0⍞000D  1  0      (⍴⍵)↑step0 ⍵                            ⍝ start with step 0.⍞000D  0  0  }⍞000D⍞000DSee also: mdf cmpx time⍞000D⍞000DIndex:performance|monitor|timing|name-clash problem|Ackermann''s function⍞000DIndex;Ackermann W.' 
