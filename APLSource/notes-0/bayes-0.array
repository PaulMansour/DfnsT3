'prob ← cond ##.bayes prior                  ⍝ Bayes'' formula⍞000D⍞000DBayesian Statistics using a Fork by Steve Mansour⍞000D¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯⍞000DSuppose the probability that a person has cancer is 3%.   A certain test will be⍞000Dpositive 90% of the time when a person has cancer.   But there is a 2% chance of⍞000Da false positive. What is the probability that a person actually has the disease⍞000Dif the result is positive?  We know  P(Test|Disease) = 0.9.   What we are trying⍞000Dto find is P(Disease|Test).⍞000D⍞000DWe use the conditional rule: P(A|B) = P(A∩B)/P(B) and P(B|A) = P(A∩B)/P(A).⍞000D⍞000DFrom this we can show:⍞000D⍞000D    P(A|B) P(B) = P(A∩B) = P(B|A) P(A)⍞000D⍞000DWe can then show that: P(B|A) = P(A|B)P(B)/P(A).⍞000D⍞000DThe marginal probability P(A) = SUMi[P(A∩Bi)] = SUMi[P(A|Bi)P(Bi)]⍞000D⍞000DThis allows us to derive Bayes'' Formula:⍞000D⍞000D                     P(A|Bi)P(Bi)⍞000D        P(Bi|A) = -------------------⍞000D                  SUMi[P(A|Bi)P(Bi)]⍞000D⍞000DLet us first set the prior probabilities.⍞000D⍞000DWe can create a vector: P(Cancer), P(No Cancer)⍞000D⍞000D    C←0.03                  ⍝ Probability of Cancer⍞000D⍞000D    ⎕←PRIOR←C,1-C           ⍝ Prior probabilities⍞000D0.03 0.97⍞000D⍞000DNow let us set the conditional probabilities.⍞000DAgain, we create a vector: P(Positive|Cancer), P(Postive|No Cancer)⍞000D⍞000D    COND←0.9 0.02           ⍝ Conditional probabilities⍞000D⍞000DNow let find the Bayesian probabilities.⍞000DThe result will be a vector: P(Cancer|Positive),P(No Cancer|Positive).⍞000D⍞000DObserve that Bayes'' Formula above consists of a product divided by an inner pro-⍞000Dduct. Let us define the function bayes as a fork:⍞000D⍞000D    bayes ← × ÷ +.×         ⍝ times div sumProduct⍞000D⍞000DWe the use the conditional probabilities as the left argument and the prior⍞000Dprobabilities as the right argument:⍞000D⍞000D    COND bayes PRIOR        ⍝ Bayes Formula⍞000D0.5819 0.4181⍞000D⍞000DThe answer is quite surprising. Given that the test is positive, the probability⍞000Dof cancer is less than 60%  which means there is greater than a 40%  chance that⍞000Dthe patient does not have cancer.⍞000D⍞000DBayes'' formula  can  be applied to situations where there are more than two out-⍞000Dcomes.   Consider  the  following table showing the breakdown of students by Sex⍞000D(F=Female,M=Male) and Party (D=Democrat, I=Independent, R=Republican):⍞000D⍞000D     frequency show D.Sex D.Party⍞000D⍞000D Count     |         D         I         R |   Total⍞000D ------------------------------------------|--------⍞000D F         |         3         2         4 |       9⍞000D M         |         8         9        12 |      29⍞000D ------------------------------------------|--------⍞000D Total     |        11        11        16 |      38⍞000D⍞000DSuppose we know that Pr(Sex|Party)  what is Pr(Party|Sex)? From Bayes'' Formula⍞000Dwe need the prior probabilities for Female:⍞000D⍞000D    ⎕←PRIORF←11 11 16÷38        ⍝ Pr(Party)⍞000D0.28947 0.28947 0.42105⍞000D⍞000DWe also need the conditional probabilities for female given party:⍞000D⍞000D    ⎕←CONDF←3 2 4÷11 11 16      ⍝ Pr(F|D),Pr(F|I),Pr(F|R)⍞000D0.27273 0.18182 0.25⍞000D⍞000DApplying Bayes'' formula, we obtain a vector of posterior probabilities:⍞000D⍞000D    CONDF bayes PRIORF          ⍝ Pr(D|F),Pr(I|F),Pr(R|F)⍞000D0.33333 0.22222 0.44444⍞000D⍞000DObserve that we can obtain the same result by dividing the joint frequencies by⍞000Dthe marginal frequency for female:⍞000D⍞000D    ⎕←3 2 4÷9                   ⍝ Pr(Party|Female)⍞000D0.33333 0.22222 0.44444⍞000D⍞000DIndex:Bayes formula⍞000DIndex;Mansour S.M.|Bayes T.' 
